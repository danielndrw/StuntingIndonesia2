# -*- coding: utf-8 -*-
"""train_model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11vr-WhBZMnyQY7POmNkpU2-zP1vHQTY1
"""

# ============================================================
# TRAINING PIPELINE (sinkron dengan data mentah Excel)
# ============================================================
import pandas as pd
import numpy as np
import os, joblib
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBRegressor
import json # Import the json library here

os.makedirs("models", exist_ok=True)

# === Load Data
df = pd.read_excel("DATA_SUM_STUNTING.xlsx")

# === Rename kolom mentah ke format standar
df.rename(columns={
    "Angka Harapan Hidup (AHH) Menurut Provinsi dan Jenis Kelamin (Tahun)": "Angka_Harapan_Hidup",
    "Persentase Rumah Tangga yang Memiliki Akses terhadap Sanitasi Layak Menurut Provinsi dan Klasifikasi Desa (Persen)": "Akses_Sanitasi_Layak",
    "Rumah Tangga yang Memiliki Akses Terhadap Sumber Air Minum Layak": "Akses_Air_Layak",
    "Persentase Rumah Tangga dengan Sumber Air Minum Air Dalam Kemasan": "Air_Kemasan",
    "Indeks Pembangunan Manusia": "IPM",
    "Prevalensi Ketidakcukupan Konsumsi Pangan (Persen)": "Konsumsi_Pangan_Tidak_Cukup",
    "Realisasi Jumlah Keluarga Penerima Manfaat (KPM) Bantuan Sosial Pangan (BANSOS PANGAN)": "Jumlah_KPM_Bansos",
    "Realisasi Anggaran Bantuan Sosial Pangan (BANSOS PANGAN) (Rp)": "Anggaran_Bansos",
    "Angka Melek Aksara Penduduk 15-59 Tahun Menurut Provinsi": "Melek_Aksara",
    "Tingkat Pengangguran Terbuka Menurut Provinsi (Persen)": "Tingkat_Pengangguran",
    "Persentase Anak Umur 12-23 Bulan yang Menerima Imunisasi Dasar Lengkap Menurut Provinsi (Persen)": "Imunisasi_Lengkap",
    "Rata-Rata Lama Sekolah Penduduk Umur 15 Tahun ke Atas Menurut Provinsi": "Lama_Sekolah",
    "Garis Kemiskinan Makanan (Rupiah/Kapita/Bulan) Menurut Provinsi dan Daerah": "Garis_Kemiskinan_Makanan",
    "Indeks Kedalaman Kemiskinan (P1) Menurut Provinsi dan Daerah (Persen)": "Kedalaman_Kemiskinan"
}, inplace=True)

# ------------------------------------------------------------
# 1) Cleansing — sesuai file aslimu
# ------------------------------------------------------------
# Imputasi per provinsi (mean by group)
df = df.groupby('Provinsi').apply(lambda g: g.fillna(g.mean(numeric_only=True))).reset_index(drop=True)

# Hapus duplikat
df.drop_duplicates(inplace=True)

# IQR capping untuk semua kolom numerik
num_cols = df.select_dtypes(include=np.number).columns.tolist()
for col in num_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lo = Q1 - 1.5 * IQR
    hi = Q3 + 1.5 * IQR
    df[col] = np.clip(df[col], lo, hi)

# ------------------------------------------------------------
# 2) Feature Engineering — mengikuti pipeline kamu
# ------------------------------------------------------------
# Log transform (hindari log(0) dg +1)
if 'Anggaran_Bansos' in df.columns:
    df['log_Anggaran_Bansos'] = np.log1p(df['Anggaran_Bansos'])
if 'Jumlah_KPM_Bansos' in df.columns:
    df['log_Jumlah_KPM_Bansos'] = np.log1p(df['Jumlah_KPM_Bansos'])
if 'Garis_Kemiskinan_Makanan' in df.columns:
    df['log_Garis_Kemiskinan_Makanan'] = np.log1p(df['Garis_Kemiskinan_Makanan'])

# Interaksi & rasio
df['IPM_x_LamaSekolah']   = df['IPM'] * df['Lama_Sekolah']
df['AksesGabungan']        = df['Akses_Air_Layak'] * df['Akses_Sanitasi_Layak']
df['Pengangguran_per_IPM'] = df['Tingkat_Pengangguran'] / (df['IPM'] + 1e-6)
df['Bansos_per_KPM']       = np.where(df['Jumlah_KPM_Bansos'] > 0,
                                      df['Anggaran_Bansos'] / df['Jumlah_KPM_Bansos'],
                                      df['Anggaran_Bansos'])
df['Konsumsi_vs_IPM']      = df['Konsumsi_Pangan_Tidak_Cukup'] / (df['IPM'] + 1e-6)

# Daftar fitur
FEATURES_BASE = [
    'IPM','Akses_Sanitasi_Layak','Akses_Air_Layak','Air_Kemasan',
    'Konsumsi_Pangan_Tidak_Cukup','Jumlah_KPM_Bansos','Anggaran_Bansos',
    'Melek_Aksara','Tingkat_Pengangguran','Imunisasi_Lengkap',
    'Lama_Sekolah','Garis_Kemiskinan_Makanan','Kedalaman_Kemiskinan'
]
FEATURES_EXTRA = [
    'log_Anggaran_Bansos','log_Jumlah_KPM_Bansos','log_Garis_Kemiskinan_Makanan',
    'IPM_x_LamaSekolah','AksesGabungan','Pengangguran_per_IPM',
    'Bansos_per_KPM','Konsumsi_vs_IPM'
]
FEATURES = [c for c in FEATURES_BASE + FEATURES_EXTRA if c in df.columns]

# Pastikan ada kolom target
if 'Stunting' not in df.columns:
    raise ValueError("Kolom target 'Stunting' tidak ditemukan di dataset.")

# ------------------------------------------------------------
# 3) CLUSTERING — Pipeline(StandardScaler -> KMeans)
#    (fit pakai FEATURES_BASE agar stabil & tidak terlalu high-dim)
# ------------------------------------------------------------
X_cluster = df[FEATURES_BASE].copy()
cluster_pipe = Pipeline([
    ("scaler", StandardScaler(with_mean=True, with_std=True)),
    ("kmeans", KMeans(n_clusters=3, random_state=42, n_init="auto"))
])
cluster_pipe.fit(X_cluster)
# Simpan pipeline
joblib.dump(cluster_pipe, "models/cluster_model.pkl")

# ------------------------------------------------------------
# 4) KLASIFIKASI — RandomForestClassifier
#    Label: Sehat (1) jika Stunting < mean & AHH > mean, else 0
# ------------------------------------------------------------
if 'Angka_Harapan_Hidup' not in df.columns:
    raise ValueError("Kolom 'Angka_Harapan_Hidup' tidak ditemukan untuk membuat label sehat/tidak sehat.")

mean_stunting = df['Stunting'].mean()
mean_ahh = df['Angka_Harapan_Hidup'].mean()
df['Label_Sehat'] = np.where(
    (df['Stunting'] < mean_stunting) & (df['Angka_Harapan_Hidup'] > mean_ahh), 1, 0
)

X_cls = df[FEATURES].copy()
y_cls = df['Label_Sehat'].astype(int)

# Pakai DataFrame agar scikit-learn mengisi feature_names_in_
Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_cls, y_cls, test_size=0.25, random_state=42, stratify=y_cls)
clf = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42)
clf.fit(Xc_train, yc_train)
joblib.dump(clf, "models/classification_model.pkl")

# ------------------------------------------------------------
# 5) REGRESI — XGBRegressor (param stabil & cepat)
# ------------------------------------------------------------
X_reg = df[FEATURES].copy()
y_reg = df['Stunting'].copy()

Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_reg, y_reg, test_size=0.25, random_state=42)
xgb = XGBRegressor(
    n_estimators=600, learning_rate=0.05, max_depth=8,
    subsample=0.8, colsample_bytree=0.8, random_state=42, eval_metric="rmse"
)
xgb.fit(Xr_train, yr_train)
joblib.dump(xgb, "models/regression_model.pkl")

# ------------------------------------------------------------
# 6) Simpan metadata fitur agar app bisa “safe-predict”
# ------------------------------------------------------------
meta = {
    "features_base": FEATURES_BASE,
    "features_extra": FEATURES_EXTRA,
    "features_all": FEATURES,
}
with open("models/expected_features.json", "w", encoding="utf-8") as f:
    json.dump(meta, f, ensure_ascii=False, indent=2)

print("✅ Selesai! Model tersimpan di folder /models:")
print("   - models/cluster_model.pkl  (Pipeline: StandardScaler -> KMeans)")
print("   - models/classification_model.pkl (RandomForestClassifier)")
print("   - models/regression_model.pkl    (XGBRegressor)")
print("   - models/expected_features.json  (metadata fitur)")